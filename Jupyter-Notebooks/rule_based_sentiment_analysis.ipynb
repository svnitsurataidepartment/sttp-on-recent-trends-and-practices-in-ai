{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65a9999d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Sentiment Analysis of a sentence using Sentiwordnet scores.\"\"\"\n",
    "# Extended the code available at https://stackoverflow.com/questions/38263039/sentiwordnet-scoring-with-python\n",
    "from sys import argv\n",
    "from nltk import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Convert the PENN Treebank POS tags to Wordnet tags.\"\"\"\n",
    "    tag = pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wn.ADJ,\n",
    "                \"N\": wn.NOUN,\n",
    "                \"V\": wn.VERB,\n",
    "                \"R\": wn.ADV}\n",
    "    return tag_dict.get(tag, wn.NOUN)\n",
    "\n",
    "\n",
    "def get_sentiment_score_of_review(sentence, common=True):\n",
    "    # 1. Tokenize the sentence\n",
    "    # 2. Lemmatize the tokens\n",
    "    # 3. Get the POS tag for each token\n",
    "    # 4. Get the synsets for each token\n",
    "    # 5. Get the SentiWordNet score for each synset\n",
    "    # 6. Calculate the sentiment score for the sentence\n",
    "    # 7. Return the sentiment score\n",
    "    tokens = word_tokenize(sentence)    \n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    sentiment_score = 0.0\n",
    "    for word in tokens:\n",
    "        tag = get_wordnet_pos(word)\n",
    "        item_res = lemmatizer.lemmatize(word, tag)\n",
    "        if not item_res:\n",
    "            continue\n",
    "        \n",
    "        synsets = wn.synsets(item_res, pos=tag)\n",
    "        if len(synsets) == 0:\n",
    "            print(\"No synsets exist for the\", word)\n",
    "            continue\n",
    "        \n",
    "        # Take the first, the most common\n",
    "        if common:\n",
    "            synset = synsets[0]\n",
    "            swn_synset = swn.senti_synset(synset.name())\n",
    "            sentiment_score += swn_synset.pos_score() - swn_synset.neg_score()\n",
    "        else:\n",
    "            # Else take the best sentiment score\n",
    "            sentiment_scores = []\n",
    "            for synset in synsets:\n",
    "                swn_synset = swn.senti_synset(synset.name())\n",
    "                senti_score = swn_synset.pos_score() - swn_synset.neg_score()\n",
    "                sentiment_scores.append(senti_score)\n",
    "            sentiment_score += max(sentiment_scores)\n",
    "\n",
    "    return sentiment_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3a133c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No synsets exist for the The\n",
      "No synsets exist for the that\n",
      "No synsets exist for the ,\n",
      "No synsets exist for the but\n",
      "No synsets exist for the the\n",
      "No synsets exist for the .\n",
      "The input sentence is: The movie was not that good, but the acting was great.\n",
      "Sentiment score of the sentence is: 1.875\n",
      "The sentiment of the sentence is positive\n"
     ]
    }
   ],
   "source": [
    "sentence = \"The movie was not that good, but the acting was great.\"\n",
    "sentiment_score = get_sentiment_score_of_review(sentence, common=False)\n",
    "print('The input sentence is:', sentence)\n",
    "print('Sentiment score of the sentence is:', sentiment_score)\n",
    "if sentiment_score > 0:\n",
    "    print('The sentiment of the sentence is positive')\n",
    "elif sentiment_score == 0:\n",
    "    print('The sentiment of the sentence is neutral')\n",
    "else:\n",
    "    print('The sentiment of the sentence is negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6746c998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vaderSentiment\n",
      "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl.metadata (572 bytes)\n",
      "Requirement already satisfied: requests in /data/miniconda/envs/my_env/lib/python3.12/site-packages (from vaderSentiment) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /data/miniconda/envs/my_env/lib/python3.12/site-packages (from requests->vaderSentiment) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /data/miniconda/envs/my_env/lib/python3.12/site-packages (from requests->vaderSentiment) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /data/miniconda/envs/my_env/lib/python3.12/site-packages (from requests->vaderSentiment) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /data/miniconda/envs/my_env/lib/python3.12/site-packages (from requests->vaderSentiment) (2025.1.31)\n",
      "Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
      "Installing collected packages: vaderSentiment\n",
      "Successfully installed vaderSentiment-3.3.2\n"
     ]
    }
   ],
   "source": [
    "! pip install vaderSentiment\n",
    "# Importing the SentimentIntensityAnalyzer from the vaderSentiment package\n",
    "# This package is used for sentiment analysis based on the VADER (Valence Aware Dictionary\n",
    "# and sEntiment Reasoner) algorithm.\n",
    "# VADER is particularly effective for analyzing sentiments expressed in social media,\n",
    "# such as tweets, reviews, and other short texts.\n",
    "# It provides a simple and efficient way to determine the sentiment polarity of a given text.\n",
    "# It assigns a sentiment score to the text, indicating whether the sentiment is positive,\n",
    "# negative, or neutral.\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ae64db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_scores(sentence):\n",
    "    \"\"\"Get the sentiment scores of a sentence using VADER.\"\"\"\n",
    "    # Create a SentimentIntensityAnalyzer object\n",
    "    # This object will be used to calculate the sentiment scores\n",
    "    # for the input sentence.\n",
    "    # It uses the VADER algorithm to analyze the sentiment of the text.\n",
    "    # The VADER algorithm is designed to work well with short texts,\n",
    "    # such as tweets, reviews, and other social media content.\n",
    "    # It provides a compound score that summarizes the overall sentiment,\n",
    "    # as well as individual scores for positive, negative, and neutral sentiments.\n",
    "    # The compound score is a normalized score that ranges from -1 (most negative) to 1 (most positive).\n",
    "    # The positive, negative, and neutral scores represent the proportion of the text that is positive, negative, and neutral, respectively.\n",
    "    # The scores are calculated based on the presence of specific words and their associated sentiment values.\n",
    "    # The SentimentIntensityAnalyzer object is initialized with a pre-defined lexicon of words and their sentiment values.\n",
    "    # It uses this lexicon to analyze the sentiment of the input text.\n",
    "    # The object can be reused for multiple sentences without needing to reinitialize it.\n",
    "    # This makes it efficient for processing large amounts of text.\n",
    "    # The SentimentIntensityAnalyzer object can be used to analyze the sentiment of any text\n",
    "    sid_obj = SentimentIntensityAnalyzer()\n",
    "    sentiment_dict = sid_obj.polarity_scores(sentence)\n",
    "\n",
    "    print(f\"Sentiment Scores: {sentiment_dict}\")\n",
    "    print(f\"Negative Sentiment: {sentiment_dict['neg']*100}%\")\n",
    "    print(f\"Neutral Sentiment: {sentiment_dict['neu']*100}%\")\n",
    "    print(f\"Positive Sentiment: {sentiment_dict['pos']*100}%\")\n",
    "    \n",
    "    if sentiment_dict['compound'] >= 0.05:\n",
    "        print(\"Overall Sentiment: Positive\")\n",
    "    elif sentiment_dict['compound'] <= -0.05:\n",
    "        print(\"Overall Sentiment: Negative\")\n",
    "    else:\n",
    "        print(\"Overall Sentiment: Neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7273c878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statement:\n",
      "Sentiment Scores: {'neg': 0.0, 'neu': 0.571, 'pos': 0.429, 'compound': 0.5423}\n",
      "Negative Sentiment: 0.0%\n",
      "Neutral Sentiment: 57.099999999999994%\n",
      "Positive Sentiment: 42.9%\n",
      "Overall Sentiment: Positive\n",
      "\n",
      "Statement:\n",
      "Sentiment Scores: {'neg': 0.408, 'neu': 0.395, 'pos': 0.197, 'compound': -0.3818}\n",
      "Negative Sentiment: 40.8%\n",
      "Neutral Sentiment: 39.5%\n",
      "Positive Sentiment: 19.7%\n",
      "Overall Sentiment: Negative\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStatement:\")\n",
    "sentence = \"Shweta played well in the match as usual.\"\n",
    "sentiment_scores(sentence)\n",
    "\n",
    "print(\"\\nStatement:\")\n",
    "sentence = \"I am feeling sad today.\"\n",
    "sentiment_scores(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce940ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
